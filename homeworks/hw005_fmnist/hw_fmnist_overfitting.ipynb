{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## NN Overfitting and How to Fix It\n",
        "\n",
        "##### Credits: [Radoslav Neychev](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "from collections import OrderedDict\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "qDTyj0hr9hwV"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "def parse_pytorch_model(model, device):\n",
        "    H, W = 28, 28\n",
        "    sample_input = torch.randn(1, 1, H, W).to(device=device)\n",
        "    supported_modules = [\n",
        "        nn.Linear, nn.Flatten, nn.Dropout, nn.Dropout2d,\n",
        "        nn.ReLU, nn.LeakyReLU,\n",
        "        nn.Conv1d, nn.Conv2d,\n",
        "        nn.BatchNorm1d, nn.BatchNorm2d,\n",
        "        nn.MaxPool2d, nn.AvgPool2d,\n",
        "        nn.AdaptiveAvgPool2d, nn.AdaptiveMaxPool2d,\n",
        "    ]\n",
        "    def register_hook(module):\n",
        "        def hook(module, input, output):\n",
        "            module_idx = len(model_dict[\"layers\"])\n",
        "            if any([isinstance(module, instance) for instance in supported_modules]):\n",
        "                model_dict[\"layers\"].append(\n",
        "                    {\n",
        "                        \"index\": module_idx,\n",
        "                        \"layer\": {\n",
        "                            \"type\": module.__class__.__name__,\n",
        "                            \"params\": str(module),\n",
        "                        }\n",
        "                    }\n",
        "                )\n",
        "        if (\n",
        "            not isinstance(module, nn.Sequential)\n",
        "            and not isinstance(module, nn.ModuleList)\n",
        "        ):\n",
        "            hooks.append(module.register_forward_hook(hook))\n",
        "\n",
        "    model_dict = {\n",
        "        \"model_name\": model.__class__.__name__,\n",
        "        \"layers\": []\n",
        "    }\n",
        "    hooks = []\n",
        "    model.apply(register_hook)\n",
        "    _ = model(sample_input)\n",
        "    # remove hooks\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "    return model_dict\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "EtJPyw4p9hwW"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq2zbnH19hwW"
      },
      "source": [
        "Load file `hw_overfitting_data_dict.npy` (link is on the task page), it will be used to generate submissions. Code below helps to load it (in case error occurs, download the file manually).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzY5nmNO9hwX",
        "outputId": "5df4a388-6c95-44a8-d45c-b1727587d677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-16 16:35:39--  https://github.com/girafe-ai/ml-course/blob/26s_harbour/homeworks/hw005_fmnist/hw_overfitting_data_dict.npy\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy.5’\n",
            "\n",
            "hw_overfitting_data     [ <=>                ] 181.29K  1022KB/s    in 0.2s    \n",
            "\n",
            "2025-12-16 16:35:40 (1022 KB/s) - ‘hw_overfitting_data_dict.npy.5’ saved [185639]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/blob/26s_harbour/homeworks/hw005_fmnist/hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "4Fiu-vfY9hwX"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "### Task #1: Creating and training a model (Separation)\n",
        "Let's go back to the simple image classification task which was discussed earlier. But now we will utilize the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset. Let's use full dataset fot this task.\n",
        "\n",
        "__Your first task: implement the entire model training pipeline and reach accuracy baseline of $\\geq 88.5\\%$ on the test set.__\n",
        "\n",
        "There is no code for training the model in this task. There are only a few tests that will help you debug your solution. You may use notebook practice from previous class as a reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "P2FPprpF9hwY"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "aYcL28OsgSq8",
        "outputId": "0c4cc646-7c46-471a-f427-ed7b1e5eb51c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 7')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJ9FJREFUeJzt3Xt0VOW9//HP5DZckgwGyA0ChshFRbFFQbwgSkoSl8ptHUTsEqgHqg0cgaPVtBVEqznFU+oN9XdOe0hbQTz0J1Bt5VQDCUcNWFBEl5UCBgEhUdBkQiDXeX5/8HPqmAB5hoQnCe/XWnutzJ7nO/s7m5182LN3nniMMUYAAJxlEa4bAACcmwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwgg4Czbu3evPB6PCgoKrGsfeugheTweHT58uNX6mTFjhs4///xWez2gpQggtCsFBQXyeDzaunWr61bQAkVFRfJ4PCddHn30Udctoh2Lct0AgI7rwgsv1O9///sm63//+9/rL3/5i8aNG+egK3QUBBCAsCUlJen73/9+k/WLFy/WwIEDdcUVVzjoCh0FH8Gh3ZsxY4ZiY2O1b98+3XTTTYqNjVWfPn20bNkySdIHH3ygG264Qd27d1f//v21cuXKkPovv/xS9957ry655BLFxsYqPj5eOTk5ev/995ts69NPP9Utt9yi7t27KzExUfPnz9f//M//yOPxqKioKGTsli1blJ2dLZ/Pp27duum6667TW2+9FdZ73LFjh2bMmKEBAwaoS5cuSk5O1g9+8AMdOXKk2fGHDx/WlClTFB8fr549e+qee+5RTU1Nk3EvvPCChg8frq5duyohIUFTp07V/v37T9vPoUOH9PHHH6u+vt76vbzzzjvavXu3br/9dutanFsIIHQIjY2NysnJUVpampYsWaLzzz9fc+bMUUFBgbKzs3X55ZfrF7/4heLi4nTHHXeotLQ0WPvJJ59o7dq1uummm7R06VLdd999+uCDD3Tdddfp4MGDwXHV1dW64YYb9MYbb+hf/uVf9NOf/lRvv/227r///ib9bNiwQaNHj5bf79eiRYv02GOPqaKiQjfccIPeeecd6/f3+uuv65NPPtHMmTP19NNPa+rUqVq1apVuvPFGNfcXU6ZMmaKamhrl5+frxhtv1FNPPaXZs2eHjHn00Ud1xx13aODAgVq6dKnmzZunwsJCjR49WhUVFafsJy8vTxdeeKE+++wz6/eyYsUKSSKAcHoGaEeWL19uJJm//vWvwXXTp083ksxjjz0WXPfVV1+Zrl27Go/HY1atWhVc//HHHxtJZtGiRcF1NTU1prGxMWQ7paWlxuv1mocffji47pe//KWRZNauXRtcd/z4cTNkyBAjyWzcuNEYY0wgEDADBw40WVlZJhAIBMceO3bMpKenm+9973unfI+lpaVGklm+fHlI7be9+OKLRpLZtGlTcN2iRYuMJHPLLbeEjP3Rj35kJJn333/fGGPM3r17TWRkpHn00UdDxn3wwQcmKioqZP306dNN//79Q8Z9vc9LS0tP+V6+raGhwSQlJZkRI0ZY1eHcxBkQOox//ud/Dn7do0cPDR48WN27d9eUKVOC6wcPHqwePXrok08+Ca7zer2KiDhxqDc2NurIkSOKjY3V4MGD9e677wbHrV+/Xn369NEtt9wSXNelSxfNmjUrpI/t27dr165dmjZtmo4cOaLDhw/r8OHDqq6u1tixY7Vp0yYFAgGr99a1a9fg1zU1NTp8+LCuvPJKSQrp8Wu5ubkhj+fOnStJ+vOf/yxJevnllxUIBDRlypRgf4cPH1ZycrIGDhyojRs3nrKfgoICGWOsb88uLCxUeXk5Zz9oEW5CQIfQpUsX9e7dO2Sdz+dT37595fF4mqz/6quvgo8DgYCefPJJPfvssyotLVVjY2PwuZ49ewa//vTTT5WRkdHk9S644IKQx7t27ZIkTZ8+/aT9VlZW6rzzzmvhuztxnWrx4sVatWqVPv/88yav9W0DBw4MeZyRkaGIiAjt3bs32KMxpsm4r0VHR7e4NxsrVqxQZGSkbr311jZ5fXQuBBA6hMjISKv15hvXTR577DE9+OCD+sEPfqBHHnlECQkJioiI0Lx586zPVCQFax5//HFddtllzY6JjY21es0pU6bo7bff1n333afLLrtMsbGxCgQCys7OblGP3w7NQCAgj8ej1157rdl9ZNtfSxw/flxr1qxRZmamkpKSWv310fkQQOj0/vCHP+j666/Xb37zm5D1FRUV6tWrV/Bx//799dFHH8kYE/IDfffu3SF1GRkZkqT4+HhlZmaecX9fffWVCgsLtXjxYi1cuDC4/uszrebs2rVL6enpIT0GAoHgR2YZGRkyxig9PV2DBg064x5b4o9//KOqqqr4+A0txjUgdHqRkZFN7iRbvXp1kzu8srKy9Nlnn+mPf/xjcF1NTY3+8z//M2Tc8OHDlZGRoX//93/X0aNHm2zviy++sO5PUpMen3jiiZPWfH0L+teefvppSVJOTo4kadKkSYqMjNTixYubvK4x5qS3d38tnNuwV65cqW7dumnixIktrsG5jTMgdHo33XSTHn74Yc2cOVNXXXWVPvjgA61YsUIDBgwIGffDH/5QzzzzjG677Tbdc889SklJ0YoVK9SlSxdJ//iYKyIiQr/+9a+Vk5Ojiy++WDNnzlSfPn302WefaePGjYqPj9crr7zS4v7i4+M1evRoLVmyRPX19erTp4/+8pe/hNxK/m2lpaW65ZZblJ2drZKSEr3wwguaNm2ahg0bJunEGdDPf/5z5eXlae/evZowYYLi4uJUWlqqNWvWaPbs2br33ntP+vp5eXn67W9/q9LS0hbdiPDll1/qtdde0+TJk9vk4z10TgQQOr2f/OQnqq6u1sqVK/XSSy/pu9/9rv70pz/pgQceCBkXGxurDRs2aO7cuXryyScVGxurO+64Q1dddZUmT54cDCJJGjNmjEpKSvTII4/omWee0dGjR5WcnKyRI0fqhz/8oXWPK1eu1Ny5c7Vs2TIZYzRu3Di99tprSk1NbXb8Sy+9pIULF+qBBx5QVFSU5syZo8cffzxkzAMPPKBBgwbpV7/6lRYvXixJSktL07hx40Lu9GsNq1evVn19vaZNm9aqr4vOzWO+fX4OIMQTTzyh+fPn68CBA+rTp4/rdoBOgwACvuH48eNNfifnO9/5jhobG/X3v//dYWdA58NHcMA3TJo0Sf369dNll12myspKvfDCC/r444+D08sAaD0EEPANWVlZ+vWvf60VK1aosbFRF110kVatWsUvVgJtgI/gAABO8HtAAAAnCCAAgBPt7hpQIBDQwYMHFRcX12R+KwBA+2eMUVVVlVJTU4Mz0Ten3QXQwYMHlZaW5roNAMAZ2r9/v/r27XvS59tdAMXFxUmSrtGNilLbTBkPAGg7DarXm/pz8Of5ybRZAC1btkyPP/64ysrKNGzYMD399NMaMWLEaeu+/tgtStGK8hBAANDh/P97q093GaVNbkJ46aWXtGDBAi1atEjvvvuuhg0bpqysrCZ/aAsAcO5qkwBaunSpZs2apZkzZ+qiiy7S888/r27duum//uu/2mJzAIAOqNUDqK6uTtu2bQv5Q10RERHKzMxUSUlJk/G1tbXy+/0hCwCg82v1ADp8+LAaGxub/EnepKQklZWVNRmfn58vn88XXLgDDgDODc5/ETUvL0+VlZXBZf/+/a5bAgCcBa1+F1yvXr0UGRmp8vLykPXl5eVKTk5uMt7r9crr9bZ2GwCAdq7Vz4BiYmI0fPhwFRYWBtcFAgEVFhZq1KhRrb05AEAH1Sa/B7RgwQJNnz5dl19+uUaMGKEnnnhC1dXVmjlzZltsDgDQAbVJAN1666364osvtHDhQpWVlemyyy7T+vXrm9yYAAA4d7W7vwfk9/vl8/k0RuOZCQEAOqAGU68irVNlZaXi4+NPOs75XXAAgHMTAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBOtHkAPPfSQPB5PyDJkyJDW3gwAoIOLaosXvfjii/XGG2/8YyNRbbIZAEAH1ibJEBUVpeTk5LZ4aQBAJ9Em14B27dql1NRUDRgwQLfffrv27dt30rG1tbXy+/0hCwCg82v1ABo5cqQKCgq0fv16PffccyotLdW1116rqqqqZsfn5+fL5/MFl7S0tNZuCQDQDnmMMaYtN1BRUaH+/ftr6dKluvPOO5s8X1tbq9ra2uBjv9+vtLQ0jdF4RXmi27I1AEAbaDD1KtI6VVZWKj4+/qTj2vzugB49emjQoEHavXt3s897vV55vd62bgMA0M60+e8BHT16VHv27FFKSkpbbwoA0IG0egDde++9Ki4u1t69e/X2229r4sSJioyM1G233dbamwIAdGCt/hHcgQMHdNttt+nIkSPq3bu3rrnmGm3evFm9e/du7U0BADqwVg+gVatWtfZLAgA6IeaCAwA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAn2vwP0gFnyhNlf5h6wvwjh4Hq6rDqzoa6rMutaz69KTKsbQ156gvrmsZdn4S1rbMhsocvrLrGispW7qT1BK79Tlh1Ef/7Xit3Ej7OgAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEs2Hj7PJ4rEtMQ8NZqQnXvkVXWddcmfOBdc2v0/7Duub3VcnWNZJ00U2fWdf88Jf3WNckPvO2dU042vOs1pLkLbb/d/p5/+fC2taEP9n/Ow3M3RLWtk6HMyAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcILJSCFFRIZXF2i0rzEmvG1ZOjZxZFh1Nzz0pnXNxOh11jVVgS7WNbP3j7auCch+8ldJessz0Lpma94z9hvKsy+5fOs065radxLsNyTp+IA665rtWU9b1xxssP++KG+Mta6RpO9dscO6Zm9YWzo9zoAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkmI23PPGFMJBnOZJ/hTCp6Fu3/w1DrmvdHPRvWtp7+yn4Szl3Hk6xr/A1drWuSvH7rmuiI8P5tI2R/HN114Frrmn/q+Y51zf8OL7Cu6Xp5jHVNuP5aa7+t/z02yLqmd1SVdY0kze5dbF3zwDWzrcYHGmqkktNP0ssZEADACQIIAOCEdQBt2rRJN998s1JTU+XxeLR27dqQ540xWrhwoVJSUtS1a1dlZmZq165drdUvAKCTsA6g6upqDRs2TMuWLWv2+SVLluipp57S888/ry1btqh79+7KyspSTU3NGTcLAOg8rG9CyMnJUU5OTrPPGWP0xBNP6Gc/+5nGjx8vSfrd736npKQkrV27VlOnTj2zbgEAnUarXgMqLS1VWVmZMjMzg+t8Pp9GjhypkpKSZmtqa2vl9/tDFgBA59eqAVRWViZJSkoKvS01KSkp+Ny35efny+fzBZe0tLTWbAkA0E45vwsuLy9PlZWVwWX//v2uWwIAnAWtGkDJycmSpPLy8pD15eXlwee+zev1Kj4+PmQBAHR+rRpA6enpSk5OVmFhYXCd3+/Xli1bNGrUqNbcFACgg7O+C+7o0aPavXt38HFpaam2b9+uhIQE9evXT/PmzdPPf/5zDRw4UOnp6XrwwQeVmpqqCRMmtGbfAIAOzjqAtm7dquuvvz74eMGCBZKk6dOnq6CgQD/+8Y9VXV2t2bNnq6KiQtdcc43Wr1+vLl26tF7XAIAOz2NMOLNXth2/3y+fz6cxGq8oT3SL6zzR9hMAmvo66xr8Q+C671jXdH/4oHXNzYnvW9d8dCzVukYKb5LQ3jH2k0LWm0jrmnBEeML79o5UwLomnIlP91T3tq6pabSfQzlgwpjYV5Ivxv4X6LtH2v9cGdyt+buET+VYILwJVifGb7euyb1jjtX4hoYabXrzEVVWVp7yur7zu+AAAOcmAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnLCfVrad6owzW0f1sZ/Red9t51vXXPlP9rNNS9KsxP+wrtlV1/xfxj2VLVUDrGu8EQ3WNZKU5PWHVWcrQvazVEd77GebjvTYz2othddfl4h665preuyyromLtJ+huovHvjdJqgrY/xmZOmP/Y/Voo/12Pq3paV0jSRkJ9jO+f/4du5rGWo/05unHcQYEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE50mslIIwdlWNfsuSMxrG11GVphXTMiZZ91zc0JRdY1Q2K+sK559vB11jWS9H/Kr7euSelSaV0TH2U/+WS4AsZjXdMYxv/jwplYNJzJPsOZVFSSArLfDxFhTnxqqyqMiTu/MHFhbStg7P9tv2zobl2T7rX/vk2IrraukaQVVfY/9+pj7cY3RrdsHGdAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOBEu52MtC7zOwpEtXzSwcvzt1lv4/qY7dY1knQ0jMkQw/HW0UHWNX9puMS6pkf0MesaSTovyr7uWCDGuiZSZ2eSS0mK8NhP3hmhszOxaDgTmIarPtDC2SS/4Vij17qmrNZnXRPO5K/hTDIbrvPC+H46UJdgXVNvIq1rJGmI95B1je28pxG1LRxn3QkAAK2AAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE6028lI902SIrq2fPyTCSXW21jx1ZXWNZJ0vNF+osZwhDP5ZPeoFs4C+A1Hw5hEUpK8EQ3WNeFMwlkfsJ90MZxJRcMV6bGfLPVwfax1TV3A/ts1wXYWyf8vLrLGuua8KPttXdjVviYmjO+LLh774y7cuogwjoeYMCa0rTHh/RwKZxLTPr/72Gp8Q6BOf2vBOM6AAABOEEAAACesA2jTpk26+eablZqaKo/Ho7Vr14Y8P2PGDHk8npAlOzu7tfoFAHQS1gFUXV2tYcOGadmyZScdk52drUOHDgWXF1988YyaBAB0PtZXNXNycpSTk3PKMV6vV8nJyWE3BQDo/NrkGlBRUZESExM1ePBg3X333Tpy5MhJx9bW1srv94csAIDOr9UDKDs7W7/73e9UWFioX/ziFyouLlZOTo4aG5u/zTA/P18+ny+4pKWltXZLAIB2qNV/D2jq1KnBry+55BJdeumlysjIUFFRkcaOHdtkfF5enhYsWBB87Pf7CSEAOAe0+W3YAwYMUK9evbR79+5mn/d6vYqPjw9ZAACdX5sH0IEDB3TkyBGlpKS09aYAAB2I9UdwR48eDTmbKS0t1fbt25WQkKCEhAQtXrxYkydPVnJysvbs2aMf//jHuuCCC5SVldWqjQMAOjbrANq6dauuv/764OOvr99Mnz5dzz33nHbs2KHf/va3qqioUGpqqsaNG6dHHnlEXm94840BADonjzHm7M3a2AJ+v18+n0/XXLdIUVFdWlzXdeFB620NiD1sXSNJc3oXWdfsb7C/tnWk0X7CygN1Pa1rqhpbvp+/KZxJDWvDmFAzHOFMlCpJvqhj1jVxEfYTdyZEHbWu6RFh31s4k79K0ugwDom3auwn4Xyjaqh1zV+/6m9ds6u8t3WNJNUdjbGuiTlkP0lowkf2P4YTSg5Z10hSQ+mnYdVZbcPUq0jrVFlZecrr+swFBwBwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACfOztTEYYgq3q4oT8tnlf1syFXW2whstJ9tWpLuib7Tumbngu7WNf80bJt1TU78Duuaa7uEN3N0pMf+/y+Nxn7G5HCE05sk1Rr72aP/Vmf/np4sz7SuKXp/iHVN4pvhfYv3fO3v1jWNh4+EtS179rNAnx9GTXsX3ndteCK6dbMbb+qkFkzezhkQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADjhMcYY1018k9/vl8/n0xiNt5qMNBzVk0eGVed7t8y6pqH007C21Z55omOsayKTE61rTFevdY3Hf9S6RpIaysrDqgPORER3+8mKA8drwtvWRQOtaz6/6jyr8Y11Nfpg+U9VWVmp+Pj4k/di3QkAAK2AAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE5EuW7gZDxRUfJ4Wt6eaWiw3kb3/7vFukaSzKAM65ojs0ZZ1xzv5bGu6VZmP7esb2+tdY0kxWwvta5p2H8grG2dNRGR1iWRA9Ota46M6G1dcyzF/nioiw9vruFAGD8Zunxp319EGIdeQzf7mi5HwtsPnkb7mtqe9vvBY//jSw3285dKkrqW2++LxBU7rMY3mLoWjeMMCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcaLeTkZqGBhmPxaR+NmPPUOPf91jX9AyjJhxRfftY19QMTg5rW1/lDLauqe9u/+8UsJ8fVCYqvOMhusp+osZuX9jPJBm3334Wzl6vf2Zd01BWbl3T3kUlJ1nXGF9cWNvy1NXbFzXYz2BqqqqsaxorKq1rwhWwHW9att84AwIAOEEAAQCcsAqg/Px8XXHFFYqLi1NiYqImTJignTt3hoypqalRbm6uevbsqdjYWE2ePFnl5Z3vYwAAwJmxCqDi4mLl5uZq8+bNev3111VfX69x48apuro6OGb+/Pl65ZVXtHr1ahUXF+vgwYOaNGlSqzcOAOjYrG5CWL9+fcjjgoICJSYmatu2bRo9erQqKyv1m9/8RitXrtQNN9wgSVq+fLkuvPBCbd68WVdeeWXrdQ4A6NDO6BpQZeWJuzASEhIkSdu2bVN9fb0yMzODY4YMGaJ+/fqppKSk2deora2V3+8PWQAAnV/YARQIBDRv3jxdffXVGjp0qCSprKxMMTEx6tGjR8jYpKQklZWVNfs6+fn58vl8wSUtLS3clgAAHUjYAZSbm6sPP/xQq1atOqMG8vLyVFlZGVz2799/Rq8HAOgYwvpF1Dlz5ujVV1/Vpk2b1Ldv3+D65ORk1dXVqaKiIuQsqLy8XMnJzf+yo9frldfrDacNAEAHZnUGZIzRnDlztGbNGm3YsEHp6ekhzw8fPlzR0dEqLCwMrtu5c6f27dunUaNGtU7HAIBOweoMKDc3VytXrtS6desUFxcXvK7j8/nUtWtX+Xw+3XnnnVqwYIESEhIUHx+vuXPnatSoUdwBBwAIYRVAzz33nCRpzJgxIeuXL1+uGTNmSJJ+9atfKSIiQpMnT1Ztba2ysrL07LPPtkqzAIDOw2OMsZ99sQ35/X75fD6N0XhFeaJdtwMAsNRg6lWkdaqsrFR8fPxJxzEXHADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnrAIoPz9fV1xxheLi4pSYmKgJEyZo586dIWPGjBkjj8cTstx1112t2jQAoOOzCqDi4mLl5uZq8+bNev3111VfX69x48apuro6ZNysWbN06NCh4LJkyZJWbRoA0PFF2Qxev359yOOCggIlJiZq27ZtGj16dHB9t27dlJyc3DodAgA6pTO6BlRZWSlJSkhICFm/YsUK9erVS0OHDlVeXp6OHTt20teora2V3+8PWQAAnZ/VGdA3BQIBzZs3T1dffbWGDh0aXD9t2jT1799fqamp2rFjh+6//37t3LlTL7/8crOvk5+fr8WLF4fbBgCgg/IYY0w4hXfffbdee+01vfnmm+rbt+9Jx23YsEFjx47V7t27lZGR0eT52tpa1dbWBh/7/X6lpaVpjMYryhMdTmsAAIcaTL2KtE6VlZWKj48/6biwzoDmzJmjV199VZs2bTpl+EjSyJEjJemkAeT1euX1esNpAwDQgVkFkDFGc+fO1Zo1a1RUVKT09PTT1mzfvl2SlJKSElaDAIDOySqAcnNztXLlSq1bt05xcXEqKyuTJPl8PnXt2lV79uzRypUrdeONN6pnz57asWOH5s+fr9GjR+vSSy9tkzcAAOiYrK4BeTyeZtcvX75cM2bM0P79+/X9739fH374oaqrq5WWlqaJEyfqZz/72Sk/B/wmv98vn8/HNSAA6KDa5BrQ6bIqLS1NxcXFNi8JADhHMRccAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMCJKNcNfJsxRpLUoHrJOG4GAGCtQfWS/vHz/GTaXQBVVVVJkt7Unx13AgA4E1VVVfL5fCd93mNOF1FnWSAQ0MGDBxUXFyePxxPynN/vV1pamvbv36/4+HhHHbrHfjiB/XAC++EE9sMJ7WE/GGNUVVWl1NRURUSc/EpPuzsDioiIUN++fU85Jj4+/pw+wL7GfjiB/XAC++EE9sMJrvfDqc58vsZNCAAAJwggAIATHSqAvF6vFi1aJK/X67oVp9gPJ7AfTmA/nMB+OKEj7Yd2dxMCAODc0KHOgAAAnQcBBABwggACADhBAAEAnCCAAABOdJgAWrZsmc4//3x16dJFI0eO1DvvvOO6pbPuoYceksfjCVmGDBniuq02t2nTJt18881KTU2Vx+PR2rVrQ543xmjhwoVKSUlR165dlZmZqV27drlptg2dbj/MmDGjyfGRnZ3tptk2kp+fryuuuEJxcXFKTEzUhAkTtHPnzpAxNTU1ys3NVc+ePRUbG6vJkyervLzcUcdtoyX7YcyYMU2Oh7vuustRx83rEAH00ksvacGCBVq0aJHeffddDRs2TFlZWfr8889dt3bWXXzxxTp06FBwefPNN1231Oaqq6s1bNgwLVu2rNnnlyxZoqeeekrPP/+8tmzZou7duysrK0s1NTVnudO2dbr9IEnZ2dkhx8eLL754Fjtse8XFxcrNzdXmzZv1+uuvq76+XuPGjVN1dXVwzPz58/XKK69o9erVKi4u1sGDBzVp0iSHXbe+luwHSZo1a1bI8bBkyRJHHZ+E6QBGjBhhcnNzg48bGxtNamqqyc/Pd9jV2bdo0SIzbNgw1204JcmsWbMm+DgQCJjk5GTz+OOPB9dVVFQYr9drXnzxRQcdnh3f3g/GGDN9+nQzfvx4J/248vnnnxtJpri42Bhz4t8+OjrarF69Ojjmb3/7m5FkSkpKXLXZ5r69H4wx5rrrrjP33HOPu6ZaoN2fAdXV1Wnbtm3KzMwMrouIiFBmZqZKSkocdubGrl27lJqaqgEDBuj222/Xvn37XLfkVGlpqcrKykKOD5/Pp5EjR56Tx0dRUZESExM1ePBg3X333Tpy5IjrltpUZWWlJCkhIUGStG3bNtXX14ccD0OGDFG/fv069fHw7f3wtRUrVqhXr14aOnSo8vLydOzYMRftnVS7mw372w4fPqzGxkYlJSWFrE9KStLHH3/sqCs3Ro4cqYKCAg0ePFiHDh3S4sWLde211+rDDz9UXFyc6/acKCsrk6Rmj4+vnztXZGdna9KkSUpPT9eePXv0k5/8RDk5OSopKVFkZKTr9lpdIBDQvHnzdPXVV2vo0KGSThwPMTEx6tGjR8jYznw8NLcfJGnatGnq37+/UlNTtWPHDt1///3auXOnXn75ZYfdhmr3AYR/yMnJCX596aWXauTIkerfv7/++7//W3feeafDztAeTJ06Nfj1JZdcoksvvVQZGRkqKirS2LFjHXbWNnJzc/Xhhx+eE9dBT+Vk+2H27NnBry+55BKlpKRo7Nix2rNnjzIyMs52m81q9x/B9erVS5GRkU3uYikvL1dycrKjrtqHHj16aNCgQdq9e7frVpz5+hjg+GhqwIAB6tWrV6c8PubMmaNXX31VGzduDPn7YcnJyaqrq1NFRUXI+M56PJxsPzRn5MiRktSujod2H0AxMTEaPny4CgsLg+sCgYAKCws1atQoh525d/ToUe3Zs0cpKSmuW3EmPT1dycnJIceH3+/Xli1bzvnj48CBAzpy5EinOj6MMZozZ47WrFmjDRs2KD09PeT54cOHKzo6OuR42Llzp/bt29epjofT7YfmbN++XZLa1/Hg+i6Illi1apXxer2moKDAfPTRR2b27NmmR48epqyszHVrZ9W//uu/mqKiIlNaWmreeustk5mZaXr16mU+//xz1621qaqqKvPee++Z9957z0gyS5cuNe+995759NNPjTHG/Nu//Zvp0aOHWbdundmxY4cZP368SU9PN8ePH3fcees61X6oqqoy9957rykpKTGlpaXmjTfeMN/97nfNwIEDTU1NjevWW83dd99tfD6fKSoqMocOHQoux44dC4656667TL9+/cyGDRvM1q1bzahRo8yoUaMcdt36Trcfdu/ebR5++GGzdetWU1paatatW2cGDBhgRo8e7bjzUB0igIwx5umnnzb9+vUzMTExZsSIEWbz5s2uWzrrbr31VpOSkmJiYmJMnz59zK233mp2797tuq02t3HjRiOpyTJ9+nRjzIlbsR988EGTlJRkvF6vGTt2rNm5c6fbptvAqfbDsWPHzLhx40zv3r1NdHS06d+/v5k1a1an+09ac+9fklm+fHlwzPHjx82PfvQjc95555lu3bqZiRMnmkOHDrlrug2cbj/s27fPjB492iQkJBiv12suuOACc99995nKykq3jX8Lfw8IAOBEu78GBADonAggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwIn/B46rf2lJhIXtAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Define your model in the code block below. Please don't make it too complicated, don't use more than 4 layers (it can be even less actually). Your main goal is to train the model and exceed `accuracy` baseline of 88.5%.\n",
        "\n",
        "__ATTENTION, your model has to be defined in `model_task_1` variable. It should use batches of input tensors of shape (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Don't forget to move your model to the `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23772a76-f8ba-4100-8317-37d933bf7bea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (4): ReLU()\n",
              "  (5): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Local unit tests for sanity check are given below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "d7889402-fab3-4ac0-fa2d-ea4c6a727436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Set up model hyperparameters for training. It's worth adjusting `learning rate` parameter as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29741632-ec45-43d2-bdf8-fe4637eba671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.5286\n",
            "Epoch 2/10, Loss: 0.3721\n",
            "Epoch 3/10, Loss: 0.3317\n",
            "Epoch 4/10, Loss: 0.3065\n",
            "Epoch 5/10, Loss: 0.2889\n",
            "Epoch 6/10, Loss: 0.2729\n",
            "Epoch 7/10, Loss: 0.2575\n",
            "Epoch 8/10, Loss: 0.2472\n",
            "Epoch 9/10, Loss: 0.2349\n",
            "Epoch 10/10, Loss: 0.2243\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_task_1.parameters(), lr=0.0005)\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model_task_1.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_data_loader:\n",
        "      x, y = batch[0].to(device), batch[1].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      y_predicted = model_task_1(x)\n",
        "      loss = criterion(y_predicted, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_data_loader):.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Don't forget to read the great [docs](https://pytorch.org/docs/stable/index.html) and [tutorials](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Evaluate accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a618296-9071-4b3a-9c2d-ab5ad423515b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.92378\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d1f7f8-3e5c-49e7-d429-620f018377bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8897\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Asserts for passing accuracy baseline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoD1D_9g9hwa"
      },
      "source": [
        "Note that code below expected your model to be defined in `model_task_1` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKxL3mjK9hwb",
        "outputId": "3b9e3dd4-71a9-4b96-9e69-1879e02ad22b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(model_task_1, device),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BND2XIkmDiqc",
        "outputId": "cf743813-2c9f-46ca-a744-6fbe2a642ed3"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'hw_overfitting_data_dict.npy', 'submission_dict_task_1.json', 'FashionMNIST', '.ipynb_checkpoints', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2NP5atR9hwb"
      },
      "source": [
        "### Task #2: Overfitting (Initiation)\n",
        "We're still working with the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset. Now the task is to demonstrate model overfitting on the training set. In other words we need to demonstrate classification accuracy (not the loss value!), which is significantly higher for the training set in comparison with the testing set.\n",
        "\n",
        "Please note that in task #3 you will have to fix this model (reduce overfitting) using regularization, so don't overdo it!\n",
        "\n",
        "__Your second task: implement model training pipeline to demonstrate model ovefitting for the training set.__\n",
        "\n",
        "You can reuse some training code from above. There are a few tests further to help you check your solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe2zlsvZ9hwb"
      },
      "source": [
        "Note that for this task model has to be defined in variable `model_task_2`.\n",
        "\n",
        "Don't use `Dropout` and `BatchNorm` for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "B_vhkfiR9hwb"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_2 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pQ7HK-h9hwb",
        "outputId": "0ce50e05-7887-4e44-decf-0000daacf6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.5058\n",
            "Epoch 2/20, Loss: 0.3673\n",
            "Epoch 3/20, Loss: 0.3289\n",
            "Epoch 4/20, Loss: 0.3044\n",
            "Epoch 5/20, Loss: 0.2848\n",
            "Epoch 6/20, Loss: 0.2713\n",
            "Epoch 7/20, Loss: 0.2562\n",
            "Epoch 8/20, Loss: 0.2483\n",
            "Epoch 9/20, Loss: 0.2333\n",
            "Epoch 10/20, Loss: 0.2268\n",
            "Epoch 11/20, Loss: 0.2166\n",
            "Epoch 12/20, Loss: 0.2111\n",
            "Epoch 13/20, Loss: 0.2017\n",
            "Epoch 14/20, Loss: 0.1967\n",
            "Epoch 15/20, Loss: 0.1932\n",
            "Epoch 16/20, Loss: 0.1843\n",
            "Epoch 17/20, Loss: 0.1819\n",
            "Epoch 18/20, Loss: 0.1733\n",
            "Epoch 19/20, Loss: 0.1721\n",
            "Epoch 20/20, Loss: 0.1643\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "model_task_2.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_task_2.parameters(), lr=0.001)\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model_task_2.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_data_loader:\n",
        "        x, y = batch[0].to(device), batch[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_predicted = model_task_2(x)\n",
        "        loss = criterion(y_predicted, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_data_loader):.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heBKjrQB9hwb"
      },
      "source": [
        "NN architecture check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "e77pohAm9hwb"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_2 = []\n",
        "for element in parse_pytorch_model(model_task_2, device).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
        "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
        "    layers_task_2.append(layer_name)\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbEyxdv89hwb"
      },
      "source": [
        "Estimate accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXdFi42y9hwb",
        "outputId": "a2ee1bc3-a079-4d90-e0f0-106f7762de9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.93875\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd04MaP19hwb",
        "outputId": "31277fd6-fe3b-4161-ae91-b0f2d6172eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8883\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fdpUm_L9hwb"
      },
      "source": [
        "Test that there is definitely overfitting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "wIchD8_q9hwb"
      },
      "outputs": [],
      "source": [
        "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
        "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert (\n",
        "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
        "), \"Test accuracy should be at least 0.04 lower that train.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x26XGgQD9hwc"
      },
      "source": [
        "Note once again that for the code below to work your model has to be defined in `model_task_2` variable.\n",
        "\n",
        "Also note that `submission_dict` variable already has saved results from task #1. If it does not, reload them from the saved file to this variable before running the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LXHpLTc9hwh",
        "outputId": "be747174-9541-4740-be70-4a3cc4c91685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_tasks_1_and_2.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_2\": parse_pytorch_model(model_task_2, device),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwGo8UPB9hwh"
      },
      "source": [
        "### Task #3: Fix the model (Return)\n",
        "We're still working with [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Finally, let's fix overfitting issue for the model from task#2. By fixing it means to achieve classification accuracy difference of 0.015 (=1.5%) for training and testing accuracy using a new updated model.\n",
        "\n",
        "Note that model architecture in task#3 should not be very different from task#2! You can use Batchnorm, Dropout, data augmentation and also reduce the channel number. You can not reduce the number of layers!\n",
        "\n",
        "\n",
        "__Your third and final task: fix the model and/or training pipeline to fix overfitting.__\n",
        "\n",
        "Once again you can reuse model training code. As usual there are a few tests below for sanity check."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uh2qhaN9hwh"
      },
      "source": [
        "Note that for this task model has to be defined in variable `model_task_3`.\n",
        "\n",
        "Code below will also access `layers_task_2` variable. Define it if it was not defined before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWbcoxPN9hwh",
        "outputId": "4e0ca0a2-7172-43ec-ef21-aa0807715e24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Dropout(p=0.3, inplace=False)\n",
              "  (4): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (5): ReLU()\n",
              "  (6): Dropout(p=0.3, inplace=False)\n",
              "  (7): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (8): ReLU()\n",
              "  (9): Dropout(p=0.3, inplace=False)\n",
              "  (10): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ],
      "source": [
        "model_task_3 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "model_task_3.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zkMzOrQ9hwh"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_task_3.parameters(), lr=0.0005, weight_decay=2e-4)\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model_task_3.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_data_loader:\n",
        "        x, y = batch[0].to(device), batch[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_predicted = model_task_3(x)\n",
        "        loss = criterion(y_predicted, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_data_loader):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBK1Tojv9hwh"
      },
      "source": [
        "Check NN architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "IccP0T549hwh"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_3 = []\n",
        "for element in parse_pytorch_model(model_task_3, device).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    layers_task_3.append(layer_name)\n",
        "\n",
        "idx = 0\n",
        "for model_3_layer in layers_task_3:\n",
        "    model_2_layer = layers_task_2[idx]\n",
        "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
        "        assert (\n",
        "            model_3_layer == model_2_layer\n",
        "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
        "        idx += 1\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VXexIxn9hwh"
      },
      "source": [
        "Estimate classification accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzSaF2Cp9hwh",
        "outputId": "5e63e5cb-e79a-4490-e590-96c9a2e5b2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.92262\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGLrikzX9hwi",
        "outputId": "4c0651b7-78e7-49f7-c36c-cc2a22190ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8884\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0EXceN69hwi"
      },
      "source": [
        "Check if overfitting is still here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "GDW-FPLN9hwi",
        "outputId": "5a143698-aeb3-46eb-989f-20c35b940f38"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Test accuracy should not be lower that train more than by 0.015",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2017449451.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtrain_acc_task_3\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.865\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Test accuracy must be higher than 0.865\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m assert (\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_acc_task_3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_acc_task_3\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.015\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ), \"Test accuracy should not be lower that train more than by 0.015\"\n",
            "\u001b[0;31mAssertionError\u001b[0m: Test accuracy should not be lower that train more than by 0.015"
          ]
        }
      ],
      "source": [
        "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
        "assert (\n",
        "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
        "), \"Test accuracy should not be lower that train more than by 0.015\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20zJPQhL9hwi"
      },
      "source": [
        "Note that code below thinks that your model is defined in variable `model_task_3`.\n",
        "\n",
        "Also note that `submission_dict` variable should already have saved results from tasks #1 and #2. If it does not, reload them from the saved files before running the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lf3NXs5t9hwi"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_3\": parse_pytorch_model(model_task_3, device),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_final.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xai8JL3tgSq_"
      },
      "source": [
        "### Submit the results for automatic grading\n",
        "Submit generated files to the corresponding contest tasks:\n",
        "    \n",
        "* `submission_dict_task_1.json` to Separation\n",
        "* `submission_dict_tasks_1_and_2.json` to Initiation\n",
        "* `submission_dict_final.json` to Return."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "The task is finished! Congrats!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "py39_audio",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}